// ═══════════════════════════════════════════════════════════════════
// ██ SOAR — Self-Organized Analytical Reasoning
// ██ Type Definitions
// ═══════════════════════════════════════════════════════════════════
//
// Inspired by MIT/Meta FAIR's SOAR framework:
// "Teaching Models to Teach Themselves: Reasoning at the Edge of
//  Learnability" (Sundaram et al., 2026)
//
// Core insight: Models fail on hard problems not due to lack of
// intelligence, but because the learning signal disappears. SOAR
// uses a teacher-student decomposition where the teacher is
// rewarded based on measured student improvement, not answer quality.
// ═══════════════════════════════════════════════════════════════════

import type { InferenceConfig, InferenceMode } from '../llm/config';

// ---------------------------------------------------------------------------
// Edge-of-Learnability Detection
// ---------------------------------------------------------------------------

/** Probe result from the quick difficulty assessment */
export interface LearnabilityProbe {
  /** Raw difficulty estimate 0-1 (from query features) */
  estimatedDifficulty: number;
  /** Confidence from initial probe pass 0-1 */
  probeConfidence: number;
  /** Entropy from initial probe 0-1 */
  probeEntropy: number;
  /** Whether the query is at the edge of learnability */
  atEdge: boolean;
  /** Reason for edge detection (or why not) */
  reason: string;
  /** Recommended SOAR iteration depth */
  recommendedDepth: number;
  /** Timestamp */
  timestamp: number;
}

/** Thresholds for triggering SOAR loop */
export interface LearnabilityThresholds {
  /** Confidence below this triggers SOAR (default: 0.35) */
  confidenceFloor: number;
  /** Entropy above this triggers SOAR (default: 0.7) */
  entropyCeiling: number;
  /** Dissonance above this triggers SOAR (default: 0.6) */
  dissonanceCeiling: number;
  /** Minimum difficulty to even consider SOAR (default: 0.5) */
  difficultyFloor: number;
}

const DEFAULT_LEARNABILITY_THRESHOLDS: LearnabilityThresholds = {
  confidenceFloor: 0.35,
  entropyCeiling: 0.7,
  dissonanceCeiling: 0.6,
  difficultyFloor: 0.5,
};

// ---------------------------------------------------------------------------
// Teacher — Curriculum Generation
// ---------------------------------------------------------------------------

/** A single stepping-stone problem generated by the teacher */
export interface SteppingStone {
  /** Unique ID */
  id: string;
  /** The generated sub-problem text */
  question: string;
  /** What reasoning pattern this is meant to exercise */
  targetSkill: string;
  /** Estimated difficulty relative to original (0-1) */
  relativeDifficulty: number;
  /** Structural quality score (assessed post-generation) */
  structuralQuality: number;
  /** Whether this stone was useful (post-evaluation) */
  wasUseful: boolean | null;
  /** Order in curriculum sequence */
  order: number;
}

/** A full curriculum generated by the teacher */
export interface Curriculum {
  /** Unique curriculum ID */
  id: string;
  /** The original hard query this curriculum targets */
  targetQuery: string;
  /** Generated stepping stones */
  stones: SteppingStone[];
  /** Total generation time (ms) */
  generationTimeMs: number;
  /** Which iteration of teacher refinement this is */
  iteration: number;
  /** Teacher's reasoning about why these steps help */
  teacherRationale: string;
}

// ---------------------------------------------------------------------------
// Student — Progressive Reasoning
// ---------------------------------------------------------------------------

/** Result of the student attempting one stepping stone */
export interface StoneAttempt {
  /** ID of the stepping stone attempted */
  stoneId: string;
  /** Student's response text */
  response: string;
  /** Confidence after this attempt */
  confidenceAfter: number;
  /** Entropy after this attempt */
  entropyAfter: number;
  /** Time taken (ms) */
  durationMs: number;
  /** Whether this step contributed to reasoning context */
  contributedToContext: boolean;
}

/** Result of student's final re-attempt on the hard problem */
export interface FinalAttempt {
  /** The raw analysis produced */
  analysis: string;
  /** Confidence on the target problem */
  confidence: number;
  /** Entropy on the target problem */
  entropy: number;
  /** Dissonance on the target problem */
  dissonance: number;
  /** Health score */
  healthScore: number;
  /** Time taken (ms) */
  durationMs: number;
}

// ---------------------------------------------------------------------------
// Reward — Grounded Signal
// ---------------------------------------------------------------------------

/** Measured improvement from one SOAR iteration */
export interface SOARReward {
  /** Change in confidence (positive = improvement) */
  deltaConfidence: number;
  /** Change in entropy (negative = improvement) */
  deltaEntropy: number;
  /** Change in dissonance (negative = improvement) */
  deltaDissonance: number;
  /** Change in health score (positive = improvement) */
  deltaHealth: number;
  /** TDA persistence entropy shift */
  deltaPersistenceEntropy: number;
  /** Composite reward score: weighted combination */
  composite: number;
  /** Whether this iteration produced meaningful improvement */
  improved: boolean;
}

/** Weights for computing composite reward */
export interface RewardWeights {
  confidence: number;  // default: 0.35
  entropy: number;     // default: 0.25 (inverted: lower is better)
  dissonance: number;  // default: 0.20 (inverted: lower is better)
  health: number;      // default: 0.15
  tda: number;         // default: 0.05
}

const DEFAULT_REWARD_WEIGHTS: RewardWeights = {
  confidence: 0.35,
  entropy: 0.25,
  dissonance: 0.20,
  health: 0.15,
  tda: 0.05,
};

// ---------------------------------------------------------------------------
// OOLONG — Contradiction Detection
// ---------------------------------------------------------------------------

/** A detected contradiction between two claims */
export interface Contradiction {
  /** Unique ID */
  id: string;
  /** First claim text */
  claimA: string;
  /** Source of first claim */
  sourceA: string;
  /** Second (contradicting) claim text */
  claimB: string;
  /** Source of second claim */
  sourceB: string;
  /** Confidence that these actually contradict (0-1) */
  contradictionConfidence: number;
  /** Nature of contradiction */
  type: 'factual' | 'logical' | 'temporal' | 'scope' | 'methodological';
  /** Brief explanation of why they contradict */
  explanation: string;
}

/** Result of cross-referencing all claims (O(n^2)) */
export interface ContradictionScan {
  /** All claims extracted */
  totalClaims: number;
  /** Total comparisons made */
  totalComparisons: number;
  /** Detected contradictions */
  contradictions: Contradiction[];
  /** Overall dissonance score from contradictions */
  computedDissonance: number;
  /** Time taken (ms) */
  durationMs: number;
}

// ---------------------------------------------------------------------------
// SOAR Session — Full Loop State
// ---------------------------------------------------------------------------

/** A complete SOAR reasoning session */
export interface SOARSession {
  /** Session ID */
  id: string;
  /** The original hard query */
  targetQuery: string;
  /** Learnability probe result */
  probe: LearnabilityProbe;
  /** Curricula generated across iterations */
  curricula: Curriculum[];
  /** Stone attempts across iterations */
  attempts: StoneAttempt[];
  /** Final attempts on the hard problem */
  finalAttempts: FinalAttempt[];
  /** Rewards per iteration */
  rewards: SOARReward[];
  /** Contradiction scan (if applicable) */
  contradictionScan: ContradictionScan | null;
  /** Baseline signals (before SOAR) */
  baselineSignals: {
    confidence: number;
    entropy: number;
    dissonance: number;
    healthScore: number;
    persistenceEntropy: number;
  };
  /** Final signals (after SOAR) */
  finalSignals: {
    confidence: number;
    entropy: number;
    dissonance: number;
    healthScore: number;
    persistenceEntropy: number;
  } | null;
  /** Total iterations completed */
  iterationsCompleted: number;
  /** Maximum iterations allowed */
  maxIterations: number;
  /** Whether SOAR improved the result */
  overallImproved: boolean;
  /** Total session time (ms) */
  totalDurationMs: number;
  /** Inference mode used */
  inferenceMode: InferenceMode;
  /** Timestamp */
  startedAt: number;
  completedAt: number | null;
  /** Current status */
  status: 'probing' | 'teaching' | 'learning' | 'evaluating' | 'complete' | 'aborted';
}

// ---------------------------------------------------------------------------
// SOAR Configuration
// ---------------------------------------------------------------------------

export interface SOARConfig {
  /** Whether SOAR is enabled */
  enabled: boolean;
  /** Auto-detect edge of learnability (vs manual trigger) */
  autoDetect: boolean;
  /** Learnability thresholds */
  thresholds: LearnabilityThresholds;
  /** Maximum SOAR iterations per query */
  maxIterations: number;
  /** Number of stepping stones per curriculum */
  stonesPerCurriculum: number;
  /** Reward weights */
  rewardWeights: RewardWeights;
  /** Minimum composite reward to continue iterating */
  minRewardThreshold: number;
  /** Enable OOLONG contradiction detection */
  contradictionDetection: boolean;
  /** Maximum claims to cross-reference (caps O(n^2) cost) */
  maxContradictionClaims: number;
  /** Cost cap for API mode (estimated tokens) */
  apiCostCapTokens: number;
  /** Whether to show detailed SOAR logs in UI */
  verbose: boolean;
}

export const DEFAULT_SOAR_CONFIG: SOARConfig = {
  enabled: false,
  autoDetect: true,
  thresholds: DEFAULT_LEARNABILITY_THRESHOLDS,
  maxIterations: 3,
  stonesPerCurriculum: 3,
  rewardWeights: DEFAULT_REWARD_WEIGHTS,
  minRewardThreshold: 0.05,
  contradictionDetection: true,
  maxContradictionClaims: 20,
  apiCostCapTokens: 50000,
  verbose: false,
};

// ---------------------------------------------------------------------------
// Provider Limitations
// ---------------------------------------------------------------------------

/** Runtime limitations based on inference mode */
interface SOARLimitations {
  mode: InferenceMode;
  maxIterations: number;
  maxStonesPerCurriculum: number;
  supportsRapidIteration: boolean;
  supportsLogprobs: boolean;
  supportsWeightUpdates: boolean;
  estimatedCostPerIteration: string;
  estimatedLatencyPerIteration: string;
  learningPersistence: 'none' | 'in-context' | 'session' | 'permanent';
  limitations: string[];
  advantages: string[];
}

/** Get limitations for a given inference mode */
export function getSOARLimitations(mode: InferenceMode): SOARLimitations {
  switch (mode) {
    case 'local':
      return {
        mode: 'local',
        maxIterations: 5,
        maxStonesPerCurriculum: 5,
        supportsRapidIteration: true,
        supportsLogprobs: true,
        supportsWeightUpdates: false,
        estimatedCostPerIteration: 'Free (local compute only)',
        estimatedLatencyPerIteration: '5-30s depending on model size',
        learningPersistence: 'session',
        limitations: [
          'Smaller model capacity limits curriculum quality — a 7B teacher generates simpler stepping stones than a 70B+',
          'VRAM/memory constraints cap maximum model size',
          'No true weight updates — "learning" is context-accumulation across iterations',
          'Local models may lack the world knowledge needed for specialized domain problems',
          'Quantized models (Q4/Q5) may produce less structurally coherent curricula',
        ],
        advantages: [
          'Unlimited iterations — no cost per query, no rate limits',
          'Full control over generation parameters (temperature, top_p, repetition_penalty)',
          'Can run rapid-fire teacher-student loops (limited only by compute speed)',
          'Access to token logprobs for richer reward signal estimation',
          'No data leaves your machine — full privacy for sensitive queries',
          'Can run parallel teacher instances if VRAM allows',
        ],
      };
    case 'api':
      return {
        mode: 'api',
        maxIterations: 2,
        maxStonesPerCurriculum: 3,
        supportsRapidIteration: false,
        supportsLogprobs: false,
        supportsWeightUpdates: false,
        estimatedCostPerIteration: '~$0.02-0.15 per iteration (GPT-4o/Claude)',
        estimatedLatencyPerIteration: '3-12s per round-trip',
        learningPersistence: 'in-context',
        limitations: [
          'Each teacher-student iteration costs tokens — a 3-step SOAR loop uses 6-15x a single query\'s tokens',
          'Rate limits cap iteration speed (typically 60-500 RPM depending on tier)',
          'No weight updates — the model doesn\'t actually learn. Improvement is purely from better prompting',
          'Learning is ephemeral — resets completely between sessions. The "student" forgets everything',
          'No access to model internals (logprobs limited or unavailable). Reward estimation is coarser',
          'Context window ceiling — curriculum + sub-problems + original must fit in one window',
          'API outages/latency spikes can interrupt multi-iteration loops',
          'Cannot inspect attention patterns or hidden states for debugging',
        ],
        advantages: [
          'Access to frontier models (GPT-4o, Claude Sonnet 4) with superior reasoning capacity',
          'Teacher generates higher-quality curricula due to larger model capability',
          'Better structural coherence in stepping-stone problems',
          'Faster per-call latency than most local setups (optimized inference infrastructure)',
          'No local hardware requirements',
        ],
      };
  }
}
