# Meta-Analytical PFC

A note-taking and research app with AI-powered analytical reasoning, modeled on the executive functions of the human prefrontal cortex.

---

## What This Is

An AI research assistant that doesn't just answer questions — it *reasons about them* through a structured analytical pipeline. Every query passes through ten stages of analysis, from statistical evaluation to causal inference to Bayesian updating, producing research-grade insights with calibrated confidence.

Built as a local-first productivity app with deep notes, a research library, and background agents that learn from your work.

> **Note:** The mathematical reasoning modules (Python implementations of DerSimonian-Laird, Bradford Hill, Ripser TDA, etc.) have been extracted into a standalone project: [`meta-analytical-pipeline`](../meta-analytical-pipeline). This app uses prompt-based equivalents that encode the same analytical frameworks.

---

## Who This Is For

- **Researchers** who need structured analytical thinking applied to their questions
- **Students** building a knowledge base with AI-assisted note-taking and concept extraction
- **Anyone** who wants an AI that reasons under uncertainty rather than hallucinating through it

---

## What It Does

### Ten-Stage Analytical Pipeline

A query enters the system and passes through:

1. **Triage** — scores complexity, routes to the right depth of analysis
2. **Memory** — retrieves semantically relevant context from ChromaDB
3. **Pathway Routing** — simple, moderate, or full executive processing
4. **Statistical Analysis** — effect sizes (Cohen's d), power analysis, bias detection, MCID thresholds
5. **Causal Inference** — Bradford Hill criteria scoring, confounding analysis, counterfactual reasoning
6. **Meta-Analysis** — DerSimonian-Laird concepts, heterogeneity assessment, publication bias
7. **Bayesian Updating** — prior specification, posterior interpretation, Bayes factor analysis
8. **Synthesis** — full evidential response generation
9. **Adversarial Review** — structured five-point red-team self-critique
10. **Confidence Calibration** — uncertainty quantification starting from maximum ignorance

Stages 4-7 use **structured prompt templates** that encode mathematical frameworks as behavioral LLM instructions. The LLM reasons with the same rigor as formal statistical methods, but applied to actual research context rather than heuristically-extracted numbers.

### Note-Taking System

- Block-based editor with rich formatting (headings, code, math, quotes, callouts, lists, todos)
- Vault organization with journals
- Bi-directional page links (`[[page-ref]]`)
- AI-assisted writing (continue, summarize, expand, rewrite)
- Concept extraction and correlation mapping

### Research Library

- Paper management with Semantic Scholar integration
- Citation search and tracking
- NeurIPS-style paper review generation
- Research idea generation and novelty checking

### Background Agents (Daemon)

Five background tasks that auto-learn from your notes:

1. **Connection Finder** — discovers hidden links between notes
2. **Daily Brief** — morning summary of changes and key insights
3. **Auto-Organizer** — tags untagged pages, clusters by topic similarity
4. **Research Assistant** — identifies implicit research questions in your notes
5. **Learning Protocol** — 7-step recursive learning engine (inventory → gap-analysis → deep-dive → cross-reference → synthesis → questions → iterate)

### Steering Engine

A 3-layer hybrid system (contrastive vectors + Bayesian priors + k-NN recall) that translates your control settings into behavioral LLM directives. Adjust complexity bias, adversarial intensity, Bayesian prior strength, focus depth, and temperature — the steering engine composes these into natural-language instructions injected into the LLM system prompt.

---

## Run

```bash
cd pfc-app
npm install
npm run dev
```

Open `http://localhost:3000`.

### Inference Modes

Configure in Settings:

- **Simulation** — template-generated responses, no API keys needed (default)
- **API** — cloud LLM calls (Anthropic, OpenAI, Google) with structured analytical prompts
- **Local** — Ollama-compatible models with full steering control

### Local Models (Ollama)

```bash
# Install Ollama, then:
ollama pull qwen2.5:32b    # for 32GB machines
ollama pull qwen2.5:14b    # for 16GB machines
ollama pull llama3.1:8b     # for 8GB GPU
```

Configure the Ollama URL in Settings → Inference Mode → Local.

---

## Project Structure

```
pfc-app/
├── app/                    # Next.js pages and API routes
│   ├── (chat)/api/chat/    # Main 10-stage pipeline endpoint (SSE)
│   ├── api/                # Assistant, notes-ai, research, daemon routes
│   ├── settings/           # Configuration UI
│   ├── notes/              # Note-taking interface
│   ├── analytics/          # Dashboard and visualization
│   └── daemon/             # Background agent management
├── lib/
│   ├── engine/
│   │   ├── simulate.ts     # 10-stage pipeline orchestrator
│   │   ├── prompts/        # Structured analytical prompt templates
│   │   ├── steering/       # 3-layer hybrid steering engine
│   │   ├── soar/           # Self-Optimizing Analytical Reasoning
│   │   └── llm/            # Multi-provider LLM resolution
│   ├── db/                 # SQLite schema and queries (Drizzle ORM)
│   ├── store/              # Zustand state management (12 slices)
│   └── notes/              # Note system utilities
├── components/             # React UI components
└── daemon/                 # Background agent system
    ├── tasks/              # 5 agent task implementations
    └── scheduler.ts        # Task scheduling and lifecycle
```

---

## Tech Stack

- **Framework:** Next.js 16, React 19, TypeScript
- **State:** Zustand with localStorage persistence
- **Styling:** Tailwind CSS 4, Radix UI, Framer Motion
- **Database:** SQLite via Drizzle ORM
- **AI:** Vercel AI SDK (Anthropic, OpenAI, Google, Ollama)
- **Visualization:** D3.js
- **Search:** ChromaDB for semantic memory

---

## Docs

- [`paper.md`](paper.md) — full academic paper on the mathematical architecture
- [`PROJECT_SUMMARY.md`](PROJECT_SUMMARY.md) — architectural summary
- [`FRONTEND_SPEC.md`](FRONTEND_SPEC.md) — complete UI/UX specification
- [`RESEARCH_OVERVIEW.md`](RESEARCH_OVERVIEW.md) — research-grade explanation of signals and analytics
- [`FEEDBACK_LOOP.md`](FEEDBACK_LOOP.md) — self-improvement via the steering engine

---

*Mathematical foundations: [`paper.md`](paper.md) | Standalone implementations: [`meta-analytical-pipeline`](../meta-analytical-pipeline)*

# Design Philosophy of Front-End

I design interfaces around the belief that presentation is everything — the first visual impression determines whether a user stays, explores, and comes back. People choose Craft over Notion and Notion over Obsidian because of vibe and attention to detail. My approach fuses anchors from multiple design languages — Google Material Expressive, Notion/Obsidian, having an oled theme (like grok) and a pitch white (IA Writer, Anytype, Notion) theme was and then being able to cycle through regular dark and light modes. I use subtle arcade-style pixelated accents, natural soft palettes (brown, tan, ashy reds, light blue), and slightly bolded typography to create visual novelty without clutter. Landing pages are deliberately minimal and inviting: clean animation, cohesive color, and just enough.

![pure white](https://github.com/user-attachments/assets/8ed22610-3217-430b-920c-30898c10fb02)

![oled](https://github.com/user-attachments/assets/5cf4188b-b4b0-4452-9778-caddc076ccc8)
