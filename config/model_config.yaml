# Meta-Analytical PFC â€“ Configuration Guide
# ==========================================
#
# This file controls how the PFC system works.
# Think of it as the "control panel" for adjusting settings.
#
# If you want the system to be:
# - Faster but less thorough: increase thresholds
# - Slower but more thorough: decrease thresholds

# ============== ANTHROPIC API SETTINGS ==============
# These control which AI models we use

anthropic:
  api_key: ${ANTHROPIC_API_KEY}  # Set via environment variable
  models:
    # "Student" model - fast and cheap, good for simple questions
    simple:
      model: "claude-3-5-haiku-20241022"
      temperature: 0.5  # 0 = stick to facts, 1 = get creative
      max_tokens: 500
    
    # "Thinking student" model - smarter for complex questions
    moderate:
      model: "claude-3-7-sonnet-20250219"
      temperature: 0.6
      max_tokens: 1000
    
    # "Professor" model - smartest for really hard questions
    complex:
      model: "claude-3-7-sonnet-20250219"
      temperature: 0.5
      max_tokens: 2000


# ============== TRIAGE (ROUTING) SETTINGS ==============
# How does the system decide which expert to use?

triage:
  # If complexity is below this, use simple model
  simple_threshold: 0.20
  
  # If complexity is between these, use moderate model
  moderate_threshold: 0.30

  # If complexity is between moderate and complex threshold, use complex model
  complex_threshold: 0.45

  # If complexity is above this, use meta-analytical mode
  meta_analytical_threshold: 0.60

  # Concept-driven complexity (uses config/concepts.yaml depth + count)
  concept_depth:
    enabled: true
    count_weight: 0.08
    depth_weight: 0.12
    count_cap: 8
    max_depth: 5

  # Meta-analyzer pass (extra scrutiny for high scores)
  meta_analyzer:
    enabled: true
    threshold: 0.60
  
  # If complexity is above moderate_threshold, use complex model
  
  # Keywords that indicate research questions
  research_keywords:
    - "research"
    - "study"
    - "analysis"
    - "meta-analysis"
    - "statistical"
    - "experimental"
    - "causal"
    - "confounding"
    - "systematic review"
    - "longitudinal"
    - "cohort"
    - "biomarker"
    - "mechanistic"
    - "effect size"
    - "psychoimmunology"
    - "psychoneuroimmunology"
    - "dysautonomia"
    - "pots"
    - "vagal"
    - "hrv"
    - "hpa-axis"
    - "cytokine"
    - "ptsd"
    - "autoimmune"


# ============== REASONING SETTINGS ==============
# Settings for each reasoning engine

reasoning:
  statistical:
    # Minimum number of data points needed for analysis
    min_samples: 10
    
    # How confident should we be? 95% = 0.95
    confidence_level: 0.95
    
    # Types of effects we care about
    effect_sizes: ["cohen_d", "correlation", "odds_ratio"]
  
  causal:
    # How far back should we look for causes?
    max_lag: 5
    
    # Should we look for bidirectional relationships?
    allow_bidirectional: true
  
  bayesian:
    # How strong is our initial guess? (1.0 = moderately confident)
    prior_strength: 1.0
    
    # How much should new evidence update our belief?
    learning_rate: 0.1


# ============== MEMORY SETTINGS ==============
# How does the system remember conversations?

memory:
  # Database for storing semantic vectors
  vector_db:
    type: "chromadb"
    path: "data/memory"
    embedding_model: "all-MiniLM-L6-v2"
  
  # How many past conversations to remember?
  max_history: 100
  
  # How similar do messages need to be to count as "related"?
  similarity_threshold: 0.7


# ============== LEARNING SETTINGS ==============
# How does the system learn from hard problems?

learning:
  # If true, injects learned skills into prompts (RAG-style)
  use_retrieval: false
  # What's the minimum confidence gap to trigger learning?
  # (If we're >20% uncertain, it's worth learning)
  confidence_gap_threshold: 0.2
  
  # Executive traces (records of hard problems)
  executive_trace:
    max_traces: 1000
    storage_path: "data/executive_traces"
  
  # Pattern detection
  pattern_detector:
    # Minimum number of similar problems to call it a "pattern"
    min_cluster_size: 3
    
    # How similar do problems need to be? (0-1, lower = stricter)
    similarity_threshold: 0.5
  
  # Training example generation
  training_generator:
    # How many examples to create per skill?
    examples_per_skill: 10
    
    # Should we create variations of examples?
    augment_examples: true


# ============== VALIDATION SETTINGS ==============
# How do we check if our answers are good?

validation:
  # Adversarial review (red-team critique)
  adversarial:
    # How many different critiques to try?
    max_perturbations: 5
    
    # Should we try to break the answer?
    aggressive: true
  
  # Confidence calibration
  confidence_calibration:
    # How many confidence "buckets"? (10 = 0-10%, 10-20%, etc.)
    num_bins: 10
    
    # What's the threshold for a "confidence gap"? (answer as good as we claimed?)
    acceptable_gap: 0.05


# ============== LOGGING SETTINGS ==============
# How much should the system talk about what it's doing?

logging:
  # Level of detail: DEBUG (everything), INFO (main), WARNING (problems), ERROR (broken)
  level: "INFO"
  
  # Where to save logs
  file_path: "data/logs/pfc_system.log"
  
  # Should we log to console too?
  console_output: true

paths:
  data_dir: ./data
  training: ./data/training
  evaluation: ./data/evaluation
  memory: ./data/memory
  executive_traces: ./data/executive_traces
  learned_knowledge: ./data/learned_knowledge
