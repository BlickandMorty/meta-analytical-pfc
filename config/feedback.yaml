feedback:
  enabled: false
  buffer_path: "data/feedback/buffer.jsonl"
  max_buffer: 5000
  critique_threshold: 0.5
  dissonance_threshold: 0.4
  entropy_threshold: 0.6
  reward_weight: 1.0
  penalty_weight: 1.0
  # Placeholder training settings (for future fine-tuning)
  finetune:
    model_name: ""
    learning_rate: 5.0e-5
    batch_size: 8
    steps: 100
    output_dir: "data/feedback/finetune"
